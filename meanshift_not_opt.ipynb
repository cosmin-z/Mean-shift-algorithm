{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c12fd9",
   "metadata": {},
   "source": [
    "# Cosmin Madalin Zaharia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df7c22",
   "metadata": {},
   "source": [
    "### Implementation of findpeak and meanshift not optimazed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803e442",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5e6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import scipy.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacca0e1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148dfe0",
   "metadata": {},
   "source": [
    "According to the homework: define a <i><b>findpeak</b></i> Where data is the n-dimensional dataset consisting of p points, idx is the column index of the data point for which we wish to compute its associated density peak, and r is the search window radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5764d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeak(data, idx, r, tau = 0.01): #in for a faster speed you can decrease tau\n",
    "        \n",
    "        #peak the vector along the column\n",
    "        point = data[:,idx]\n",
    "        \n",
    "        #calculate the distance between the dataset and the point\n",
    "        distance = cdist(data.T,point.reshape(1,-1))\n",
    "        \n",
    "        #define the window size\n",
    "        window_size = np.where(distance < r)[0]\n",
    "        \n",
    "        #Now let's calculate the mean\n",
    "        #Since I want to get a (3,) vector, the axis = 1\n",
    "        mean_points = np.mean(data[:,window_size], axis=1) \n",
    "        \n",
    "        #simple euclidian distance and repeat the process above until the convergece\n",
    "        while (np.linalg.norm(point - mean_points)) > tau:\n",
    "            point = mean_points\n",
    "            distance = cdist(data.T,point.reshape(1,-1))\n",
    "            window_size = np.where(distance < r)[0]\n",
    "            mean_points = np.mean(data[:,window_size], axis=1)\n",
    "        \n",
    "        return point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c3157",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba5745",
   "metadata": {},
   "source": [
    "According to the homework: define a <i><b>meanshift</b></i> function where peaks are compared after each call to the findpeak function and for similar peaks to be merged. For our implementation of meanshift, we will consider two peaks to be the same if the distance between them is smaller than r/2. Also, if the peak of a data point is found to already exist in peaks then for simplicity its computed peak is discarded and it is given the label of the associated peak in peaks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59872ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift(data, r):\n",
    "    #define the label \n",
    "    labels = np.zeros(data.shape[1])-1 \n",
    "    peaks = []\n",
    "    \n",
    "    #first iteration\n",
    "    peak = findpeak(data, 0 , r)\n",
    "    labels[0] = 0\n",
    "    peaks.append(peak)\n",
    "    \n",
    "\n",
    "    for idx in range(1, data.shape[1]):\n",
    "        peak = findpeak(data, idx, r)\n",
    "        \n",
    "        #after you got the peak calculate the distance with the other peaks and see if it is smaller than r<2\n",
    "        distance=np.linalg.norm(peaks - peak, axis = 1)\n",
    "        similar_peaks = np.argwhere(distance < r/2)\n",
    "        \n",
    "        if len(similar_peaks) > 0:\n",
    "            labels[idx] = similar_peaks[0]\n",
    "        else:\n",
    "            #this means that we aren't the window so the peak doesn't belong to that cluster => we found a new cluster\n",
    "            peaks.append(peak)\n",
    "            labels[idx] = len(peaks)\n",
    "\n",
    "    return labels, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07886354",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd01686",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015d9b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 1., 1., 1.]),\n",
       " [array([-0.06756875,  0.04788814,  0.02778451]),\n",
       "  array([5.04987186, 4.98116882, 5.0104074 ])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('pts.mat')\n",
    "meanshift(mat[\"data\"] , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a135e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
